{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task-utils for computing CSG metrics from Climate Impacts Lab downscaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupiter.task_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01ms3fs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupiter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TaskSet, TaskInventory, TaskInstructions, TaskLauncher\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupiter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upload_s3_file\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jupiter.task_utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import s3fs\n",
    "import numpy as np\n",
    "from jupiter.task_utils import TaskSet, TaskInventory, TaskInstructions, TaskLauncher\n",
    "from jupiter.aws.s3 import upload_s3_file\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some parameters\n",
    "\n",
    "params = {\n",
    "    # Path to inventory file\n",
    "    'inventory_path' : 's3://jupiter-reference-data/CIL-Downscaled-CMIP/cmip6/cil_downscaled_cmip6_inventory.pq',\n",
    "}\n",
    "\n",
    "\n",
    "batch_queue = 'csg-global-dev-multi' #special queue for me\n",
    "taskset_name = 'test-runs-milwaukee-domains' # this is called aarona-noah-mp-hue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find expected output files\n",
    "Load the inventory file to figure out how many output files we need to loop over/should expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invdf = pd.read_parquet(params['inventory_path'])\n",
    "invdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a giant list of every GCM, experiment_id and year combination\n",
    "all_gcms = []\n",
    "all_scenarios = []\n",
    "all_years = []\n",
    "all_outpaths = []\n",
    "\n",
    "for dex, rowdat in invdf.iterrows():\n",
    "    if rowdat['experiment_id'] == 'historical':\n",
    "        years = list(np.arange(1950,2015,5))\n",
    "    else:\n",
    "        years = list(np.arange(2015,2101,5))\n",
    "    nyears = len(years)\n",
    "    all_gcms += [rowdat['source_id']]*nyears\n",
    "    all_scenarios += [rowdat['experiment_id']]*nyears\n",
    "    all_years += years\n",
    "    \n",
    "    outpaths = [f's3://jupiter-reference-data/CIL-Downscaled-CMIP/cmip6/{rowdat[\"experiment_id\"]}/{rowdat[\"source_id\"]}/{rowdat[\"source_id\"]}_{rowdat[\"experiment_id\"]}_{year}_csg_metrics.nc' for year in years]\n",
    "    all_outpaths += outpaths\n",
    "    \n",
    "params['job_indices'] = [str(x) for x in list(np.arange(len(all_gcms)))]\n",
    "params['gcms'] = all_gcms\n",
    "params['scenarios'] = all_scenarios\n",
    "params['years'] = [str(x) for x in all_years]\n",
    "params['outpaths'] = all_outpaths\n",
    "print(len(all_gcms))\n",
    "print(all_outpaths[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting task-utils YAML\n",
    "\n",
    "This dictionary should include the key components to the task-utils yaml file.  The lists of download parameters from the dataframe above are programmatically inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_str = 'python cil_downscaled_projections/run.py --gcm ${gcm} --scenario ${scenario} --year ${year} --outpath ${outpath}'\n",
    "print(cmd_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    'name' : taskset_name,\n",
    "    'labels' : {\n",
    "        'env' : 'dev',\n",
    "        'project' : 'csg',\n",
    "        'S3_ROOT' : 's3://jupiter-intern-projects/aarona', #going to point to my s3 space\n",
    "    },\n",
    "    'definitions' : params,\n",
    "    'launch_settings' : {\n",
    "        'batch' : {\n",
    "            'job_def': f'aarona-noah-mp-hue:1',\n",
    "            'queue' : batch_queue,\n",
    "            #'overrides' : {\n",
    "            #    'vcpus' : 4,\n",
    "            #    'memory' : 16000,\n",
    "            #},\n",
    "            'overrides' : {\n",
    "                \"resourceRequirements\": [\n",
    "                    {\n",
    "                        \"type\": \"MEMORY\",\n",
    "                        \"value\" : \"16000\" #MB\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"VCPU\",\n",
    "                        \"value\" : \"4\"\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'run_keys' : {\n",
    "            'command_string' : cmd_str\n",
    "        }\n",
    "    },\n",
    "    'indicators' : {\n",
    "        'completed' : {\n",
    "            'components' : ['${outpath}'],\n",
    "            'method' : 's3_sensor'\n",
    "        },\n",
    "    },\n",
    "    'loops': {\n",
    "        'job_index' : 'job_indices',\n",
    "    },\n",
    "    'mapped_loops' : {\n",
    "        'outpath' : {'job_index' : 'outpaths'},\n",
    "        'gcm' : {'job_index' : 'gcms'},\n",
    "        'scenario' : {'job_index' : 'scenarios'},\n",
    "        'year' : {'job_index' : 'years'}\n",
    "    }\n",
    "        \n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this to a yaml file\n",
    "with open(f'{taskset_name}.yaml', 'w') as outfile:\n",
    "    docs = yaml.dump(output_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with task-utils\n",
    "\n",
    "This follows the normal task-utils sequence.  Start by making an instruction list (which should also help confirm our YAML was formatted correctly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "DRY_RUN = False# if True, no batch runs will actually be launched\n",
    "\n",
    "\n",
    "ts = TaskSet(f'{taskset_name}.yaml')\n",
    "instr = TaskInstructions(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use this for the basic testing mode; just do the first X runs\n",
    "test_mode = 'basic'\n",
    "number_of_tests = 5\n",
    "\n",
    "# use this if you want your tests to comprise of one run for each value of a specified loop (or multiple loops)\n",
    "#test_mode = \"one_per_loop\"\n",
    "#loop_names = [\"peril\"]\n",
    "\n",
    "# use this if you want to specify a custom query to define your test set\n",
    "#test_mode = \"query\"\n",
    "#test_query = f\"(tileid in {testset}) and (projection_scenario == 'ssp585') and (metric == 'windSpeed500yr')\"#\" and scenario == 'worst_one'\"\n",
    "\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "load_existing_inventory_for_tests = True\n",
    "\n",
    "task_inv = TaskInventory(ts, load_existing = load_existing_inventory_for_tests)\n",
    "if test_mode == 'basic': task_inv.assign_basic_test_set(number_in_set = number_of_tests)\n",
    "elif test_mode == 'one_per_loop': task_inv.assign_test_set_by_loop(loops=loop_names, combinations=True)\n",
    "elif test_mode == 'query': task_inv.assign_test_set_by_query(query_str=test_query)\n",
    "else: raise ValueError(f\"test_mode {test_mode} not valid\")\n",
    "task_inv.save()\n",
    "\n",
    "task_instructions_test = TaskInstructions(ts)\n",
    "task_instructions_test.filter_tests_only()\n",
    "task_instructions_test.preview()\n",
    "print(f'Notebook DRY_RUN value is set to {DRY_RUN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch test jobs here\n",
    "\n",
    "Please use job arrays to make this easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_job_arrays = True\n",
    "job_array_split_criteria = None #'peril'\n",
    "\n",
    "## Advanced options, please do not use rashly!\n",
    "num_attempts = None\n",
    "timeout = None\n",
    "\n",
    "# See step 4 for details\n",
    "jobs_per_execution = 1\n",
    "group_criteria = None\n",
    "\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "instructions_file_test = task_instructions_test.write_instructions()\n",
    "tl_test = TaskLauncher(instructions_file_test)\n",
    "if use_job_arrays: tl_test.launch_via_aws_job_array(dry_run = DRY_RUN, split_on = job_array_split_criteria, jobs_per_execution = jobs_per_execution, group_on = group_criteria, num_attempts = num_attempts, timeout = timeout)\n",
    "else: tl_test.launch_via_aws_batch(dry_run = DRY_RUN, num_attempts = num_attempts, timeout = timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check status of test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No options here, just execute it!\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "load_existing_inventory = True\n",
    "skip_s3_datacheck = {\"completed\":1}\n",
    "also_update_batch_status = True\n",
    "batch_skip_statuses = [\"SUCCEEDED\"]\n",
    "num_processors = None\n",
    "\n",
    "task_inv = TaskInventory(ts, load_existing = load_existing_inventory)\n",
    "task_inv.update_status(skip_values = skip_s3_datacheck, also_update_batch_status = also_update_batch_status, nproc=num_processors, batch_skip_statuses = batch_skip_statuses, tests_only = True)\n",
    "task_inv.print_summary(tests_only = True)\n",
    "if also_update_batch_status: task_inv.print_batch_summary(tests_only = True)\n",
    "task_inv.save()\n",
    "#task_inv.apply_style(task_inv.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_inv.apply_style(task_inv.test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun failures of test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter_query = 'completed != 1 and LAST_KNOWN_JOB_STATUS not in [\"SUBMITTED\",\"PENDING\",\"STARTING\",\"RUNNABLE\",\"RUNNING\"] and IN_TEST_SET == True'\n",
    "filter_query = 'LAST_KNOWN_JOB_STATUS == \"FAILED\" and IN_TEST_SET == True and completed != 1'\n",
    "\n",
    "update_first = True\n",
    "skip_s3_datacheck = {'completed': 1}\n",
    "also_update_batch_status = True\n",
    "batch_skip_statuses = ['SUCCEEDED']\n",
    "num_processors = None\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "rerun_instructions = TaskInstructions(ts)\n",
    "rerun_instructions.filter_on_inventory(query = filter_query, update_first=update_first, skip_values = skip_s3_datacheck, also_update_batch_status = also_update_batch_status, nproc=num_processors, batch_skip_statuses = batch_skip_statuses)\n",
    "#rerun_instructions.filter_tests_only()\n",
    "rerun_instructions.preview()\n",
    "print(f'Notebook DRY_RUN value is set to {DRY_RUN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_instructions_file_test = rerun_instructions.write_instructions()\n",
    "tl_test = TaskLauncher(rerun_instructions_file_test)\n",
    "use_job_arrays = False\n",
    "if use_job_arrays: tl_test.launch_via_aws_job_array(dry_run = DRY_RUN, split_on = job_array_split_criteria, jobs_per_execution = jobs_per_execution, group_on = group_criteria, num_attempts = num_attempts, timeout = timeout)\n",
    "else: tl_test.launch_via_aws_batch(dry_run = DRY_RUN, num_attempts = num_attempts, timeout = timeout)\n",
    "use_job_arrays = True\n",
    "# Go back up and re-check the status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RUNNING ALL TASKS\n",
    "## Create instructions for all remaining runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create instructions and verify preview\n",
    "task_instructions = TaskInstructions(ts)\n",
    "task_instructions.filter_tests_excluded()  # comment this line if you want to run EVERYTHING, even previous tests\n",
    "#task_instructions.preview()\n",
    "print(f'Notebook DRY_RUN value is set to {DRY_RUN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch all runs\n",
    "Please use job arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_job_arrays = True\n",
    "job_array_split_criteria = None # example only, adjust for your use case\n",
    "\n",
    "## Advanced options, please do not use rashly!\n",
    "num_attempts = None\n",
    "timeout = None\n",
    "\n",
    "# Set one of these options to run multiple commands in a loop\n",
    "# within a single container execution. Your container may need \n",
    "# special code to handle this properly!\n",
    "jobs_per_execution = 5\n",
    "group_criteria = None\n",
    "\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "instructions_file = task_instructions.write_instructions()\n",
    "tl = TaskLauncher(instructions_file)\n",
    "\n",
    "if use_job_arrays: tl.launch_via_aws_job_array(dry_run = DRY_RUN, split_on = job_array_split_criteria, jobs_per_execution = jobs_per_execution, group_on = group_criteria, num_attempts = num_attempts, timeout = timeout)\n",
    "else: tl.launch_via_aws_batch(dry_run = DRY_RUN, num_attempts = num_attempts, timeout = timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_inventory = True\n",
    "skip_s3_datacheck = {'completed': 1}\n",
    "also_update_batch_status = True\n",
    "batch_skip_statuses = ['SUCCEEDED']\n",
    "num_processors = None\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "task_inv = TaskInventory(ts, load_existing = load_existing_inventory)\n",
    "task_inv.update_status(skip_values = skip_s3_datacheck, also_update_batch_status = also_update_batch_status, nproc=num_processors, batch_skip_statuses = batch_skip_statuses)\n",
    "task_inv.print_summary()\n",
    "if also_update_batch_status: task_inv.print_batch_summary()\n",
    "task_inv.save()\n",
    "#.styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_inv.apply_style(task_inv.df[task_inv.df['LAST_KNOWN_JOB_STATUS']=='FAILED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_inv.df[task_inv.df['LAST_KNOWN_JOB_STATUS']=='FAILED']['tileid'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter_query = 'succeeded != 1 and LAST_KNOWN_JOB_STATUS not in [\"SUBMITTED\",\"PENDING\",\"STARTING\",\"RUNNABLE\",\"RUNNING\"]'\n",
    "#filter_query = '(completed != 1)'\n",
    "filter_query = 'LAST_KNOWN_JOB_STATUS in [\"FAILED\"]'\n",
    "\n",
    "update_first = False\n",
    "skip_s3_datacheck = {'completed': 1}\n",
    "also_update_batch_status = False\n",
    "batch_skip_statuses = ['SUCCEEDED']\n",
    "num_processors = None\n",
    "\n",
    "###################  ↑↑   OPTIONS   ↑↑  ###################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "###################  ↓↓ DON'T TOUCH ↓↓  ###################\n",
    "\n",
    "rerun_instructions = TaskInstructions(ts)\n",
    "rerun_instructions.filter_on_inventory(query = filter_query, update_first=update_first, skip_values = skip_s3_datacheck, also_update_batch_status = also_update_batch_status, nproc=num_processors, batch_skip_statuses = batch_skip_statuses)\n",
    "rerun_instructions.preview()\n",
    "print(f'Notebook DRY_RUN value is set to {DRY_RUN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_job_arrays = True\n",
    "job_array_split_criteria = None # example only, adjust for your use case\n",
    "\n",
    "## Advanced options, please do not use rashly!\n",
    "num_attempts = None\n",
    "timeout = None\n",
    "\n",
    "# Set one of these options to run multiple commands in a loop\n",
    "# within a single container execution. Your container may need \n",
    "# special code to handle this properly!\n",
    "jobs_per_execution = 1\n",
    "group_criteria = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rerun_instructions_file = rerun_instructions.write_instructions()\n",
    "tl_test = TaskLauncher(rerun_instructions_file)\n",
    "\n",
    "if use_job_arrays: tl_test.launch_via_aws_job_array(dry_run = DRY_RUN, split_on = job_array_split_criteria, jobs_per_execution = jobs_per_execution, group_on = group_criteria, num_attempts = num_attempts, timeout = timeout)\n",
    "else: tl_test.launch_via_aws_batch(dry_run = DRY_RUN, num_attempts = num_attempts, timeout = timeout)\n",
    "    \n",
    "# Go back up and re-check the status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
